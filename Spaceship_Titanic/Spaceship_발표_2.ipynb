{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spaceship Titanic: EDA & Feature Engineering 발표자료\n",
                "\n",
                "이 노트북은 Spaceship Titanic 경진대회의 데이터 분석(EDA) 및 특성 공학(Feature Engineering) 과정을 설명하기 위한 발표 자료입니다.\n",
                "\n",
                "## 목차\n",
                "1. **데이터 로드 및 개요**\n",
                "2. **탐색적 데이터 분석 (EDA)**\n",
                "3. **결측치 처리 (Missing Values Imputation)**\n",
                "4. **파생 변수 생성 (Feature Engineering)**\n",
                "5. **인코딩 및 스케일링 (Encoding & Scaling)**\n",
                "6. **데이터 분리 (Data Split)**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드 및 개요\n",
                "\n",
                "먼저 필요한 라이브러리를 불러오고, 학습 데이터(`train.csv`)와 테스트 데이터(`test.csv`)를 로드합니다.\n",
                "두 데이터를 합쳐서(`all_data`) 전처리를 일괄적으로 수행하겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 데이터 로드\n",
                "train_df = pd.read_csv('./train.csv')\n",
                "test_df = pd.read_csv('./test.csv')\n",
                "\n",
                "# 전처리를 위해 데이터 합치기\n",
                "all_data = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
                "\n",
                "# 데이터 확인\n",
                "print(f\"전체 데이터 크기: {all_data.shape}\")\n",
                "all_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 탐색적 데이터 분석 (EDA)\n",
                "\n",
                "데이터의 특징을 파악하기 위해 주요 변수들에 대한 시각화와 분석을 진행합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 지출 금액 (TotalSpending) 분석\n",
                "승객들이 선내에서 사용한 금액의 총합(`TotalSpending`)을 계산하고, 지출 여부에 따른 생존율을 확인해봅니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 지출 항목 합계 계산\n",
                "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
                "all_data['TotalSpending'] = all_data[spending_cols].sum(axis=1)\n",
                "\n",
                "# 지출 그룹 생성 (지출 없음, 소액, 고액)\n",
                "def making_spending_group(x):\n",
                "    if x == 0:\n",
                "        return '0원 구간'\n",
                "    elif x <= 1200:\n",
                "        return '중간 지출 구간'\n",
                "    else:\n",
                "        return '고액 지출 구간'\n",
                "\n",
                "all_data['SpendingGroup'] = all_data['TotalSpending'].apply(making_spending_group)\n",
                "\n",
                "# 지출 그룹별 생존율 시각화 (Train 데이터만 사용)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(data=all_data[:len(train_df)], x='SpendingGroup', hue='Transported')\n",
                "plt.title('Transported count by Spending Group')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 고향 행성 (HomePlanet) 분석\n",
                "출신 행성별 승객 수와 생존율을 비교합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(data=all_data[:len(train_df)], x='HomePlanet', hue='Transported')\n",
                "plt.title('Transported count by HomePlanet')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 동면 여부 (CryoSleep) 분석\n",
                "동면 상태였던 승객들의 생존율이 확연히 높은지 확인합니다. 이는 매우 중요한 예측 변수가 될 것입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(data=all_data[:len(train_df)], x='CryoSleep', hue='Transported')\n",
                "plt.title('Transported count by CryoSleep')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 결측치 처리 (Missing Values Imputation)\n",
                "\n",
                "데이터에 존재하는 결측치를 다양한 논리와 통계적 방법을 사용하여 채워보겠습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3-1. CryoSleep (동면 여부) 결측치 처리\n",
                "- 지출 내역이 있다면 깨어있었으므로 `False`\n",
                "- 지출이 전혀 없다면 동면 중이었을 가능성이 높으므로 `True`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data[spending_cols].sum(axis=1) > 0), 'CryoSleep'] = False\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data[spending_cols].sum(axis=1) == 0), 'CryoSleep'] = True\n",
                "\n",
                "print(f\"CryoSleep 남은 결측치: {all_data['CryoSleep'].isna().sum()}개\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3-2. Age (나이) 결측치 처리\n",
                "나이는 전체 승객의 **중앙값(Median)**으로 채우고, 이를 바탕으로 `AgeGroup` 파생 변수를 생성합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "age_median = all_data['Age'].median()\n",
                "all_data['Age'] = all_data['Age'].fillna(age_median)\n",
                "\n",
                "def update_age_group(age):\n",
                "    if age <= 4: return 'Baby'\n",
                "    elif age <= 12: return 'Child'\n",
                "    elif age <= 19: return 'Teenager'\n",
                "    elif age <= 40: return 'Adult'\n",
                "    elif age <= 60: return 'Middle Aged'\n",
                "    else: return 'Senior'\n",
                "\n",
                "all_data['AgeGroup'] = all_data['Age'].apply(update_age_group)\n",
                "print(\"Age 결측치 처리 완료 및 AgeGroup 생성\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3-3. VIP 결측치 처리\n",
                "VIP 여부는 다음 조건들을 고려하여 `False`일 확률이 높은 경우를 먼저 채웁니다.\n",
                "- 지출액이 0원인 경우\n",
                "- 19세 이하 미성년자\n",
                "- 고향이 Earth인 경우\n",
                "- 남은 결측치는 최빈값인 `False`로 채웁니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['TotalSpending'] == 0), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['Age'] <= 19), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['HomePlanet'] == 'Earth'), 'VIP'] = False\n",
                "all_data['VIP'] = all_data['VIP'].fillna(False).astype(bool)\n",
                "\n",
                "print(f\"VIP 남은 결측치: {all_data['VIP'].isna().sum()}개\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3-4. Destination (목적지) 결측치 처리\n",
                "가장 많은 승객이 향하는 최빈값(`TRAPPIST-1e`)으로 채웁니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dest_mode = all_data['Destination'].mode()[0]\n",
                "all_data['Destination'] = all_data['Destination'].fillna(dest_mode)\n",
                "print(f\"Destination 남은 결측치: {all_data['Destination'].isna().sum()}개\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3-5. Cabin, Surname, HomePlanet (그룹 정보 활용)\n",
                "- `PassengerId`에서 `Group` 정보를 추출합니다.\n",
                "- 같은 그룹원은 가족이나 동행일 확률이 높으므로 `Surname`, `HomePlanet`, `Cabin` 정보를 공유할 가능성이 큽니다.\n",
                "- 이를 이용하여 결측치를 보간합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PassengerId에서 Group 추출, Name에서 Surname 추출\n",
                "all_data['Group'] = all_data['PassengerId'].apply(lambda x: x.split('_')[0])\n",
                "all_data['Surname'] = all_data['Name'].apply(lambda x: x.split()[-1] if pd.notna(x) else np.nan)\n",
                "\n",
                "# Surname 보정 (그룹 내 공유)\n",
                "all_data['Surname'] = all_data.groupby('Group')['Surname'].ffill().bfill()\n",
                "\n",
                "# HomePlanet 보정 (그룹 및 성씨 활용)\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].ffill().bfill()\n",
                "home_map = all_data.dropna(subset=['HomePlanet']).groupby('Surname')['HomePlanet'].agg(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['Surname'].map(home_map))\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['HomePlanet'].mode()[0])\n",
                "\n",
                "# Cabin 파생 변수 생성 및 보정\n",
                "all_data['Deck'] = all_data['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else np.nan)\n",
                "all_data['Num'] = all_data['Cabin'].apply(lambda x: x.split('/')[1] if pd.notna(x) else np.nan)\n",
                "all_data['Side'] = all_data['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else np.nan)\n",
                "\n",
                "# 같은 그룹 내 Deck, Side, Num 공유\n",
                "all_data['Deck'] = all_data.groupby('Group')['Deck'].ffill().bfill()\n",
                "all_data['Side'] = all_data.groupby('Group')['Side'].ffill().bfill()\n",
                "all_data['Num'] = pd.to_numeric(all_data['Num'], errors='coerce')\n",
                "all_data['Num'] = all_data.groupby('Group')['Num'].ffill().bfill()\n",
                "\n",
                "print(\"그룹 정보를 활용한 결측치 처리 완료\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 추가 전처리 (이상치 처리 및 컬럼 정리)\n",
                "\n",
                "- 동면 상태(`CryoSleep=True`)인 승객의 지출액은 0원이어야 하므로 강제 보정합니다.\n",
                "- 불필요한 컬럼(`PassengerId`, `Name`, `Cabin` 등)을 제거합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 이상치 처리\n",
                "all_data.loc[all_data['CryoSleep'] == 1, spending_cols] = 0\n",
                "\n",
                "# 중복 제거\n",
                "all_data = all_data.drop_duplicates()\n",
                "\n",
                "# 불필요한 컬럼 삭제\n",
                "drop_cols = ['PassengerId', 'Name', 'Cabin', 'Surname', 'Group']\n",
                "all_data = all_data.drop(columns=drop_cols, errors='ignore')\n",
                "\n",
                "print(\"최종 컬럼 목록:\", all_data.columns.tolist())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 인코딩 및 스케일링\n",
                "\n",
                "- 범주형 변수: One-Hot Encoding\n",
                "- 수치형 변수: StandardScaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# 원-핫 인코딩\n",
                "encoding_cols = ['HomePlanet', 'Destination', 'AgeGroup', 'SpendingGroup', 'Deck', 'Side']\n",
                "all_data = pd.get_dummies(all_data, columns=encoding_cols)\n",
                "\n",
                "# 불리언 타입 정수형 변환\n",
                "all_data = all_data.astype(int)\n",
                "\n",
                "# 스케일링\n",
                "scaling_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpending', 'Num']\n",
                "# GroupSize, FamilySize가 있다면 추가\n",
                "if 'GroupSize' in all_data.columns: scaling_cols.append('GroupSize')\n",
                "if 'FamilySize' in all_data.columns: scaling_cols.append('FamilySize')\n",
                "\n",
                "scaler = StandardScaler()\n",
                "all_data[scaling_cols] = scaler.fit_transform(all_data[scaling_cols])\n",
                "\n",
                "print(\"인코딩 및 스케일링 완료\")\n",
                "all_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 데이터 분리\n",
                "\n",
                "전처리가 완료된 데이터를 다시 학습용(`X`, `y`)과 테스트용(`test_final`)으로 분리합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Train/Test 분리\n",
                "X = all_data[:len(train_df)].drop(columns=['Transported'])\n",
                "y = all_data[:len(train_df)]['Transported']\n",
                "test_final = all_data[len(train_df):].drop(columns=['Transported'])\n",
                "\n",
                "# 검증 검증용 데이터셋 분리\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"X_train shape: {X_train.shape}\")\n",
                "print(f\"X_test shape: {X_test.shape}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}